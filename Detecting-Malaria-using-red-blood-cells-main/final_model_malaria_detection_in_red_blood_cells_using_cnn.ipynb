{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThabangIsaac1/Malaria/blob/main/final_model_malaria_detection_in_red_blood_cells_using_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFRpwlqYWi2I"
      },
      "source": [
        "## **Malaria Detection In Red Blood Cells Using Convulutional Neural Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy_KqBAeP7MA"
      },
      "source": [
        "Malaria is one of the most severe public health problems worlwide. It is caused by a tiny plasmodium parasite that uses mosquitoes as vectors to bite humans hence infectecting  their redblood cells, leading to adverse health effects. Moreover the manual examination using  the microscopic slide by taxonomists has become the most ineffective and tedious process that has made global responses slow leading to numerous deaths and infections. This project will entail of a proposed solution that was inspired by Laxmi Kant a machine learning enthusiast.\n",
        "\n",
        "Improvements to Laxmi Kant model include.\n",
        "\n",
        "\n",
        "1.   Code Cleaning\n",
        "2.   Accuracy improvements through a new proposed Convulutional layer, VGG 19 model, Image Augmentation and improvements using transfer learning.\n",
        "3.   Model visualisations and analytics\n",
        "\n",
        "Laxmi Kants  Repo.  https://github.com/laxmimerit/Malaria-Classification-Using-CNN/blob/master/TensorFlow_2_0_Tutorial_for_Beginners_15_Malaria_Parasite_Detection_Using_CNN.ipynb\n",
        "\n",
        "\n",
        "Improvements will be clarified in the documentation.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yxNqPT2VsBO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSqh9IaMTD6K"
      },
      "source": [
        "from IPython.display import display, Image\n",
        "display(Image(filename='/content/drive/MyDrive/Colab Notebooks/redblood.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Plw_ebDAdonN"
      },
      "source": [
        "The dataset used in this project is provided by the researchers at the Lister Hill National Center for Biomedical Communications (LHNCBC), part of the National Library of Medicine (NLM).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXnJx5031j9I"
      },
      "source": [
        "# **Library Imports of All Needed Dependencies**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcJa3dzd1ujL"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pnd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter\n",
        "import cv2\n",
        "from concurrent import futures\n",
        "import threading\n",
        "import matplotlib.pyplot as mplt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import roc_curve, auc \n",
        "from sklearn import metrics\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdOGtLN30kCf"
      },
      "source": [
        "# **Redblood Cells image dataset import & Summarization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Z93XmZWTIQ"
      },
      "source": [
        "#Load image dataset of mosquitoes from the directories into two variables categorised as - Infected and Uninfected red blood cells.\n",
        "\n",
        "main_folder = os.path.join('/content/drive/My Drive/Colab Notebooks/Red_Blood_Dataset/cell_images')\n",
        "infected_dir = os.path.join(main_folder,'Infected')\n",
        "healthy_dir = os.path.join(main_folder,'Uninfected')\n",
        "\n",
        "infected_files = glob.glob(infected_dir+'/*.png')\n",
        "healthy_files = glob.glob(healthy_dir+'/*.png')\n",
        "len(infected_files), len(healthy_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv_JtniahMBl"
      },
      "source": [
        "#View the first 5 images of Red blood cells in the dataset and also explore infected and non infected cells.\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "dataset_df = pnd.DataFrame({\n",
        "    'filename': infected_files + healthy_files,\n",
        "    'label': ['malaria'] * len(infected_files) + ['healthy'] * len(healthy_files)\n",
        "}).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "dataset_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B63dpQYW1JPj"
      },
      "source": [
        "# **Split model Dataset into training, validation, and testing data,**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD1dAHqTygjc"
      },
      "source": [
        "#Prepare data to be used for training,testing and validations accordingly\n",
        "#Using a 60:10:30 ratio.\n",
        "\n",
        "training_files, testing_files, training_labels, testing_labels = train_test_split(dataset_df['filename'].values,\n",
        "                                                                      dataset_df['label'].values,\n",
        "                                                                      test_size=0.3, random_state=42)\n",
        "training_files, validation_files, training_labels, validation_labels = train_test_split(training_files,\n",
        "                                                                    training_labels,\n",
        "                                                                    test_size=0.1, random_state=42)\n",
        "\n",
        "print(training_files.shape, validation_files.shape, testing_files.shape)\n",
        "print('Training:', Counter(training_labels), '\\nValidation:', Counter(validation_labels), '\\nTesting:', Counter(testing_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4w24HBh5fiy"
      },
      "source": [
        "# **Statics and Summarization of Training Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0mPyzKl1iDv"
      },
      "source": [
        "**Visualise image dimensons and sizes to reach consensus on best standard scales to used**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTZdhQWI52mG"
      },
      "source": [
        "#Get summary statistcs of image dimensions and orientations\n",
        "\n",
        "def get_image_shape_parallel(keyx, img, total_imgs):\n",
        "    if keyx % 5000 == 0 or keyx == (total_imgs - 1):\n",
        "        print('{}: working on the image num: {}'.format(threading.current_thread().name,\n",
        "                                                  keyx))\n",
        "    return cv2.imread(img).shape\n",
        " \n",
        "ex = futures.ThreadPoolExecutor(max_workers=None)\n",
        "traindata_inp = [(keyx, img, len(training_files)) for keyx, img in enumerate(training_files)]\n",
        "print('Initializing Image shape computation:')\n",
        "training_img_dimensions_map = ex.map(get_image_shape_parallel,\n",
        "                            [record[0] for record in traindata_inp],\n",
        "                            [record[1] for record in traindata_inp],\n",
        "                            [record[2] for record in traindata_inp])\n",
        "\n",
        "train_images_dimensions = list(training_img_dimensions_map)\n",
        "print('Minimum Dimensions:', np.min(train_images_dimensions, axis=0))\n",
        "print('Average Dimensions:', np.mean(train_images_dimensions, axis=0))\n",
        "print('Median Dimensions:', np.median(train_images_dimensions, axis=0))\n",
        "print('Maximum Dimensions:', np.max(train_images_dimensions, axis=0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-VzKR4bI1Hj"
      },
      "source": [
        "# **Image Resize and  Parallel Processing Application**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQEcdnZdKvmY"
      },
      "source": [
        "\n",
        "\n",
        "1.   Parallel Processing applied to speed up image-reading operations.\n",
        "2.   Based on summary statistics images will be scaled to standard dimensions - 125 x 125 Pixels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cu_hJ4ILki9"
      },
      "source": [
        "IMAGE_DIMENSIONS = (125, 125)\n",
        "\n",
        "def get_parallel_imagedata(idx, img, total_imgs):\n",
        "    if idx % 5000 == 0 or idx == (total_imgs - 1):\n",
        "        print('{}: working on img num: {}'.format(threading.current_thread().name,\n",
        "                                                  idx))\n",
        "    img = cv2.imread(img)\n",
        "    img = cv2.resize(img, dsize=IMAGE_DIMENSIONS,\n",
        "                     interpolation=cv2.INTER_CUBIC)\n",
        "    img = np.array(img, dtype=np.float32)\n",
        "    return img\n",
        "\n",
        "ex = futures.ThreadPoolExecutor(max_workers=None)\n",
        "training_data_inp = [(idx, img, len(training_files)) for idx, img in enumerate(training_files)]\n",
        "validation_data_inp = [(idx, img, len(validation_files)) for idx, img in enumerate(validation_files)]\n",
        "testing_data_inp = [(idx, img, len(testing_files)) for idx, img in enumerate(testing_files)]\n",
        "\n",
        "print('Unpack Training Images:')\n",
        "training_data_map = ex.map(get_parallel_imagedata,\n",
        "                        [record[0] for record in training_data_inp],\n",
        "                        [record[1] for record in training_data_inp],\n",
        "                        [record[2] for record in training_data_inp])\n",
        "training_data = np.array(list(training_data_map))\n",
        "\n",
        "print('\\nUnpack Validation Images:')\n",
        "validation_data_map = ex.map(get_parallel_imagedata,\n",
        "                        [record[0] for record in validation_data_inp],\n",
        "                        [record[1] for record in validation_data_inp],\n",
        "                        [record[2] for record in validation_data_inp])\n",
        "validation_data = np.array(list(validation_data_map))\n",
        "\n",
        "print('\\nUnpack Test Images:')\n",
        "testing_data_map = ex.map(get_parallel_imagedata,\n",
        "                        [record[0] for record in testing_data_inp],\n",
        "                        [record[1] for record in testing_data_inp],\n",
        "                        [record[2] for record in testing_data_inp])\n",
        "testing_data = np.array(list(testing_data_map))\n",
        "\n",
        "training_data.shape, validation_data.shape, testing_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7QzSRYnvIus"
      },
      "source": [
        "# **Dataset Visualization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6zRRlaGvgME"
      },
      "source": [
        "\n",
        "\n",
        "1.   Randomly visualizing sample datasets after resizing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-bauLpovwyX"
      },
      "source": [
        "mplt.figure(1 , figsize = (8 , 8))\n",
        "n = 0\n",
        "for i in range(16):\n",
        "    n += 1\n",
        "    r = np.random.randint(0 , training_data.shape[0] , 1)\n",
        "    mplt.subplot(4 , 4 , n)\n",
        "    mplt.subplots_adjust(hspace = 0.5 , wspace = 0.5)\n",
        "    mplt.imshow(training_data[r[0]]/255.)\n",
        "    mplt.title('{}'.format(training_labels[r[0]]))\n",
        "    mplt.xticks([]) , mplt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR_sxr7w3QKy"
      },
      "source": [
        "# **Configurations Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gakz5sT5Bu4"
      },
      "source": [
        "\n",
        "\n",
        "1.   Encoding the categorical class labels\n",
        "2.   Setting Batch size and epochs\n",
        "3.   Implementing Tensorflow \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC_yx1OV36VQ"
      },
      "source": [
        "NUM_CLASSES = 2\n",
        "\n",
        "\n",
        "train_imgs_scaled = training_data / 255.\n",
        "val_imgs_scaled = validation_data / 255.\n",
        "\n",
        "# encode text category labels by categorization.\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(training_labels)\n",
        "training_labels_enc = le.transform(training_labels)\n",
        "val_labels_enc = le.transform(validation_labels)\n",
        "\n",
        "print(training_labels[:6], training_labels_enc[:6])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UG2eJ8D7C0e"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "tf.__version__\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH-Nbwf3ugjt"
      },
      "source": [
        "#**Model Design**\n",
        "\n",
        "My CNN model below is similar to the one Laxmis proposed model but with major improvements to it. \n",
        "___________________________\n",
        "Laxmi's Model Dimensions:\n",
        "Total params: 406,625\n",
        "Trainable params: 406,625\n",
        "Non-trainable params: 0\n",
        "________________________\n",
        "\n",
        "\n",
        "1.   The model will be trained accordingly.\n",
        "2.   After training the model will be refined using transfer learning to improve the accuracy levels of the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss_jVf5Xuo7n"
      },
      "source": [
        "inp = tf.keras.layers.Input(shape=(125, 125, 3))\n",
        "\n",
        "conv1 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                               activation='relu', padding='same')(inp)\n",
        "pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "conv2 = tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\n",
        "                               activation='relu', padding='same')(pool1)\n",
        "pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "conv3 = tf.keras.layers.Conv2D(128, kernel_size=(3, 3),\n",
        "                               activation='relu', padding='same')(pool2)\n",
        "pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "flat = tf.keras.layers.Flatten()(pool3)\n",
        "\n",
        "hidden1 = tf.keras.layers.Dense(512, activation='relu')(flat)\n",
        "drop1 = tf.keras.layers.Dropout(rate=0.3)(hidden1)\n",
        "hidden2 = tf.keras.layers.Dense(512, activation='relu')(drop1)\n",
        "drop2 = tf.keras.layers.Dropout(rate=0.3)(hidden2)\n",
        "\n",
        "out = tf.keras.layers.Dense(1, activation='sigmoid')(drop2)\n",
        "\n",
        "model = tf.keras.Model(inputs=inp, outputs=out)\n",
        "model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeK6lqqrrhvJ"
      },
      "source": [
        "# Tensor Logs\n",
        "logdir = os.path.join('/content/drive/MyDrive/Colab Notebooks/Red_Blood_Dataset/Tensorlogs',\n",
        "                      datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLnRHh1_6LX2"
      },
      "source": [
        "#train model\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
        "                              patience=2, min_lr=0.000001)\n",
        "callbacks = [reduce_lr, tensorboard_callback]\n",
        "\n",
        "history = model.fit(x=train_imgs_scaled, y=training_labels_enc,\n",
        "                    batch_size=64,\n",
        "                    epochs=10,\n",
        "                    validation_data=(val_imgs_scaled, val_labels_enc),\n",
        "                    callbacks=callbacks,\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA6dG44XcIW0"
      },
      "source": [
        "# **Plotting the training, validation accuracy and loss curves.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RALRtRLxcPWP"
      },
      "source": [
        "**Noted Issues**\n",
        "\n",
        "\n",
        "\n",
        "1.   Validation accuracy of 96.0% \n",
        "2.   Model Overfitting based on the 99.8% training accuracy\n",
        "\n",
        "The malaria detection model proposed is promising but faces a challenge of overfitting. This means the noise or random fluctuations in the training data is picked up and learned as concepts by the model. But these concepts  do not apply  or relate to new data  thus alters the models aptitude to generalize. \n",
        "\n",
        "\n",
        "**Graphs below provide statistical point of view.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrpUsTNZnsgh"
      },
      "source": [
        "#Graphs for model performance\n",
        "\n",
        "f, (ax1, ax2) = mplt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('CNN Model Performance', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "max_epoch = len(history.history['accuracy'])+1\n",
        "epoch_list = list(range(1,max_epoch))\n",
        "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
        "ax1.set_xticks(np.arange(1, max_epoch, 5))\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
        "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(np.arange(1, max_epoch, 5))\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKdMQ8nnoCun"
      },
      "source": [
        "# **Implementing Transfer Learning & Augmentation**\n",
        "\n",
        "Transfer Learning is a deep learning is a concept of using domain knowledge from a  pretrained model and adapting it to another domain based on a targert task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOquCBUCoVoX"
      },
      "source": [
        "Our CNN model is promosing but is not satsifying looking at the accuracy levels it has. Although it is better than Laxmi Kants' model in the sense that Laxmi Kants' model had an accuracy of 93.5% whilist our achieved achieved 96.0% accuracy levels during training. But our model experienced a  problem of overfitting.\n",
        "\n",
        "To solve this we are going to image augmentation to improve our model.\n",
        "Steps\n",
        "\n",
        "\n",
        "1.   Save Our Current model\n",
        "2.   Create image augmentors to fine tune our model\n",
        "2.   Implement transfer learning and train our new model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0UjJbsmqMX2"
      },
      "source": [
        "#Save our first model\n",
        "model.save('ModelOne_cnn.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X76NfBhBpS5f"
      },
      "source": [
        "#Building Image Augmentors\n",
        "training_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
        "                                                                zoom_range=0.05,\n",
        "                                                                rotation_range=25,\n",
        "                                                                width_shift_range=0.05,\n",
        "                                                                height_shift_range=0.05,\n",
        "                                                                shear_range=0.05, horizontal_flip=True,\n",
        "                                                                fill_mode='nearest')\n",
        "\n",
        "valiation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "training_generator = training_datagen.flow(training_data, training_labels_enc, batch_size=64, shuffle=True)\n",
        "validation_generator = valiation_datagen.flow(validation_data, val_labels_enc, batch_size=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0JwQQQI0NVo"
      },
      "source": [
        "#Results from a batch of image augmentation transforms\n",
        "\n",
        "id = 0\n",
        "generated_sample = training_datagen.flow(training_data[id:id+1], training_labels[id:id+1],\n",
        "                                      batch_size=1)\n",
        "sample = [next(generated_sample) for i in range(0,5)]\n",
        "fig, ax = mplt.subplots(1,5, figsize=(16, 6))\n",
        "print('Labels:', [item[1][0] for item in sample])\n",
        "l = [ax[i].imshow(sample[i][0][0]) for i in range(0,5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufon1YsqfEoh"
      },
      "source": [
        "VGG concept \n",
        "\n",
        "This model was considered since it has been trained on a huge dataset with vast image categories hence it has learned the hierarchy of features, which are spatial-, rotational-, and translation-invariant learnt by CNN models. After building the model it will be trained using an augmented training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oefcQqtA01L1"
      },
      "source": [
        "vggmodel = tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet', \n",
        "                                        input_shape=((125, 125, 3)))\n",
        "# Freeze the layers for training\n",
        "vggmodel.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in vggmodel.layers:\n",
        "    if layer.name in ['block5_conv1', 'block4_conv1']:\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "    \n",
        "base_vgg = vggmodel\n",
        "base_out = base_vgg.output\n",
        "pool_out = tf.keras.layers.Flatten()(base_out)\n",
        "hidden1 = tf.keras.layers.Dense(512, activation='relu')(pool_out)\n",
        "drop1 = tf.keras.layers.Dropout(rate=0.3)(hidden1)\n",
        "hidden2 = tf.keras.layers.Dense(512, activation='relu')(drop1)\n",
        "drop2 = tf.keras.layers.Dropout(rate=0.3)(hidden2)\n",
        "\n",
        "out = tf.keras.layers.Dense(1, activation='sigmoid')(drop2)\n",
        "\n",
        "model = tf.keras.Model(inputs=base_vgg.input, outputs=out)\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-5),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "print(\"Total Layers:\", len(model.layers))\n",
        "print(\"Total trainable layers:\", sum([1 for l in model.layers if l.trainable]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d8YkKZIU0M3"
      },
      "source": [
        "#train model\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
        "                              patience=2, min_lr=0.000001)\n",
        "\n",
        "callbacks = [reduce_lr, tensorboard_callback]\n",
        "train_steps_per_epoch = training_generator.n // training_generator.batch_size\n",
        "val_steps_per_epoch = validation_generator.n // validation_generator.batch_size\n",
        "history = model.fit(training_generator, steps_per_epoch=train_steps_per_epoch, epochs=20,\n",
        "                              validation_data=validation_generator, validation_steps=val_steps_per_epoch,\n",
        "                              verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD1dd1sjxRbw"
      },
      "source": [
        "#Visualising model training accuracies and losses\n",
        "\n",
        "f, (ax1, ax2) = mplt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('VGG Performance Stats', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "max_epoch = len(history.history['accuracy'])+1\n",
        "epoch_list = list(range(1,max_epoch))\n",
        "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
        "ax1.set_xticks(np.arange(1, max_epoch, 5))\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
        "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(np.arange(1, max_epoch, 5))\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je-ygkMB122K"
      },
      "source": [
        "#Save final fine tuned model\n",
        "model.save('final_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seRju1IC1_3d"
      },
      "source": [
        "# **Model Evaluations**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfLAdFan2D48"
      },
      "source": [
        "1.   Test model prediction accuracies using Test Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAoUFHK52E5U"
      },
      "source": [
        "test_images_scaled = testing_data / 255.\n",
        "test_images_scaled, testing_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy1KOvoo2HhN"
      },
      "source": [
        "# Initialize saved models\n",
        "\n",
        "model1 = tf.keras.models.load_model('./ModelOne_cnn.h5')\n",
        "finalmodel = tf.keras.models.load_model('./final_model.h5')\n",
        "\n",
        "# Make Predictions on Test Data\n",
        "model1_cnn_preds = model1.predict(test_images_scaled, batch_size=512)\n",
        "model2_preds = finalmodel.predict(test_images_scaled, batch_size=512)\n",
        "\n",
        "model1_cnn_pred_labels = le.inverse_transform([1 if pred > 0.5 else 0\n",
        "                                                  for pred in model1_cnn_preds.ravel()])\n",
        "main_model2_pred_labels = le.inverse_transform([1 if pred > 0.5 else 0\n",
        "                                                  for pred in model2_preds.ravel()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haGazDVo5dcA"
      },
      "source": [
        "def get_metrics(true_labels, predicted_labels):\n",
        "    \n",
        "    return {\n",
        "        'Accuracy': np.round(\n",
        "                        metrics.accuracy_score(true_labels, \n",
        "                                               predicted_labels),\n",
        "                        4),\n",
        "        'Precision:': np.round(\n",
        "                        metrics.precision_score(true_labels, \n",
        "                                               predicted_labels,\n",
        "                                               average='weighted'),\n",
        "                        4),\n",
        "        'Recall': np.round(\n",
        "                        metrics.recall_score(true_labels, \n",
        "                                               predicted_labels,\n",
        "                                               average='weighted'),\n",
        "                        4),\n",
        "        'F1 Score:': np.round(\n",
        "                        metrics.f1_score(true_labels, \n",
        "                                               predicted_labels,\n",
        "                                               average='weighted'),\n",
        "                        4)\n",
        "    }\n",
        "    \n",
        "#Evaluate model using 4 metrics\n",
        "\n",
        "modelone_performance = get_metrics(true_labels=testing_labels, predicted_labels=model1_cnn_pred_labels)\n",
        "\n",
        "finalvgg_performance = get_metrics(true_labels=testing_labels, predicted_labels=main_model2_pred_labels)\n",
        "\n",
        "pnd.DataFrame([modelone_performance, finalvgg_performance],\n",
        "             index=['First Model CNN',  ' Fine Tuned VGG Model'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}